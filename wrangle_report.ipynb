{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Wrangle and Analyze WeRateDogs Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "> In this project WeRateDogs Twitter data is wrangled to create interesting and trustworthy analyses and visualizations. WeRateDogs is a Twitter account that rates people's dogs with a humorous comment about the dog. Using Python and its libraries, data is gathered from a variety of sources and in a variety of formats, then it is assessed for its quality and tidiness, then neccessary cleaning is done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering\n",
    "\n",
    ">**Data is gathered from following sources:**\n",
    "1. **Enhanced Twitter Archive:**\n",
    "The WeRateDogs Twitter archive contains basic tweet data for all 5000+ of their tweets, but not everything.\n",
    "2. **Image Predictions File:**\n",
    "After running every image in the WeRateDogs Twitter archive through a neural network that can classify breeds of dogs. The results are stored in a table full of image predictions. This data can be gathered from Udacity's web page\n",
    "3. **Additional Data via the Twitter API:**\n",
    "In Twitter archives data retweet count and favorite count are two of the notable column omissions. Fortunately, this additional data can be gathered by anyone from Twitter's API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Successfully gathered WeRateDogs Twitter archive data, tweet image predictions from Internet and tweet image predictions from Internet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing\n",
    ">Visual Assessment and Programatic Assessment is done on the gathered datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Quality Dimensions:**\n",
    ">1. Accuracy\n",
    "2. Completeness\n",
    "3. Consistency\n",
    "4. Validity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rules of Tidy Data:**\n",
    ">1. Each variable forms a column.\n",
    "2. Each observation forms a row.\n",
    "3. Each type of observational unit forms a table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations from accessing archive dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. tweet_id should be string(i.e. object) datatype \n",
    "2. Data is missing in the following columns: in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id, retweeted_status_timestamp, expanded_urls.\n",
    "3. in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id columns should be of string(i.e. object) datatype.\n",
    "4. retweeted_status_timestamp column should be of datetime datatype.\n",
    "5. Some of the names contain 'None' or 'a' values.\n",
    "6. Some of the values in rating_numerator column are unreasonable.\n",
    "7. Some of the values in rating_denominator column also have unreasonable values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations from accessing images dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Names of the dogs in following columns contain underscore in the place of space: p1, p2, p3 and consistency is also not maintained in the naming convention some time names are in lowercase other times camel case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations from accessing twitter dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This dataset is actually a missing part of twitter archive dataset so it needs to be merged in archive dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality Issues\n",
    "> 1. tweet_id should be of string(i.e. object) datatype \n",
    "2. sources, img_num and dogs_stage should be converted to categort datatype\n",
    "3. As we only want original ratings (no retweets) so deleting retweets\n",
    "4. Deleting tweets with no image\n",
    "5. Missing data in the following columns: in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id, retweeted_status_timestamp, expanded_urls\n",
    "5. Following columns should be of string(i.e. object) datatype: in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id. These columns could also be deleted after merging the dataset into one dataset.\n",
    "6. timestamp columns should be of datetime datatype\n",
    "7. Some of the names contain 'None' or 'a' values\n",
    "8. Names of the dogs in following columns contain underscore in the place of space: p1, p2, p3\n",
    "9. Consistency is not maintained in the naming convention some time names are in lowercase other times camel case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tidiness Issues\n",
    "> 1. In archive dataset all dogoo, floofer, pupper, puppo columns represent the same variable and could be converted into one column\n",
    "2. All the 3 dataset are different pieces of data representing information about the ratings of dogs hence they can be merged in one dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning \n",
    "> 1. All the observed quality issues and tidiness issues are removed by cleaning the datasets. Firstly the tidiness issues are removed as they are structural issues and then the quality issues are resolved.\n",
    "2. Every issue is removed by firstly defining the issue then writing the code to resolve it and then testing whether the issue is resolved or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing dataset in a csv file\n",
    "> Finally after successfully gathering data from various sources, assessing and cleaning the dataset it is stored in a csv file. So that a cleaned file can be used for the data analysis and visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">1. https://seaborn.pydata.org/tutorial.html \n",
    "2. https://stackabuse.com/reading-and-writing-json-to-a-file-in-python\n",
    "3. https://stackoverflow.com/questions/28384588/twitter-api-get-tweets-with-specific-id\n",
    "4. https://en.wikipedia.org/wiki/WeRateDogs\n",
    "5. https://stackoverflow.com/questions/12309269/how-do-i-write-json-data-to-a-file\n",
    "6. https://pandas.pydata.org/\n",
    "7. https://stackoverflow.com/questions/7370801/measure-time-elapsed-in-python?answertab=oldest#tab-top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
